# Performance Report æŒ‡æ ‡æ–‡æ¡£

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜äº† `/performance` é¡µé¢å„é¡¹æŒ‡æ ‡çš„æ•°æ®æ¥æºã€é‡‡é›†ä¾æ®å’Œè®¡ç®—ç®—æ³•ã€‚

---

## 1. åŸºç¡€ KPI æŒ‡æ ‡

### 1.1 è¯æ±‡é‡ (vocab_size)

**å®šä¹‰**: ç”¨æˆ·æ­£åœ¨å­¦ä¹ æˆ–å·²æŒæ¡çš„å•è¯æ€»æ•°

**æ•°æ®æ¥æº**: `word_proficiency` è¡¨

**è®¡ç®—å…¬å¼**:
```sql
SELECT COUNT(DISTINCT word) 
FROM word_proficiency 
WHERE status != 'new'
```

**è¯´æ˜**: ç»Ÿè®¡ `status` ä¸ä¸º `new` çš„å»é‡å•è¯æ•°é‡ã€‚çŠ¶æ€åŒ…æ‹¬:
- `new`: æ–°é‡åˆ°çš„è¯ (ä¸è®¡å…¥)
- `learning`: æ­£åœ¨å­¦ä¹ ä¸­
- `mastered`: å·²æŒæ¡

---

### 1.2 æŒæ¡ç‡ (mastery_rate)

**å®šä¹‰**: å·²æŒæ¡å•è¯å å…¨éƒ¨æ¥è§¦å•è¯çš„æ¯”ä¾‹

**æ•°æ®æ¥æº**: `word_proficiency` è¡¨

**è®¡ç®—å…¬å¼**:
```
mastery_rate = COUNT(status='mastered') / COUNT(DISTINCT word)
```

**è¯´æ˜**: åˆ†å­ä¸º `mastered` çŠ¶æ€çš„å•è¯æ•°ï¼Œåˆ†æ¯ä¸ºæ‰€æœ‰æ¥è§¦è¿‡çš„å•è¯æ€»æ•°ã€‚

---

### 1.3 ç†è§£åŠ› (comprehension_score)

**å®šä¹‰**: ç”¨æˆ·é¦–æ¬¡é‡åˆ°å•è¯æ—¶å°±ç†è§£çš„æ¯”ä¾‹ (è¶Šé«˜è¶Šå¥½)

**æ•°æ®æ¥æº**: `word_proficiency` è¡¨çš„ `huh_count` å’Œ `exposure_count`

**è®¡ç®—å…¬å¼**:
```
comprehension_score = 1 - SUM(huh_count) / SUM(exposure_count)
```

**è¯´æ˜**: 
- `huh_count`: ç”¨æˆ·ç‚¹å‡» "HUH?" æŒ‰é’®çš„æ¬¡æ•° (è¡¨ç¤ºä¸ç†è§£)
- `exposure_count`: å•è¯å‡ºç°çš„æ€»æ¬¡æ•°
- ç»“æœä¸º 0~1 ä¹‹é—´çš„å°æ•°ï¼Œä¹˜ä»¥ 100 æ˜¾ç¤ºä¸ºç™¾åˆ†æ¯”

---

### 1.4 å­¦ä¹ æ—¶é•¿ (total_study_minutes)

**å®šä¹‰**: ç”¨æˆ·ç´¯è®¡å­¦ä¹ æ—¶é—´ (åˆ†é’Ÿ)

**æ•°æ®æ¥æº**: `attempts` è¡¨çš„ `duration_seconds`

**è®¡ç®—å…¬å¼**:
```sql
SELECT SUM(duration_seconds) / 60 FROM attempts
```

**è¯´æ˜**: æ±‡æ€»æ‰€æœ‰ç»ƒä¹ æ´»åŠ¨ (quiz, scenario, mission) çš„æŒç»­æ—¶é—´ã€‚

---

## 2. V2 åŠ¨æ€æŒ‡æ ‡

### 2.1 å¾…å¤ä¹ è¯æ•° (due_reviews_count)

**å®šä¹‰**: æ ¹æ® SRS ç®—æ³•ï¼Œåˆ°æœŸéœ€è¦å¤ä¹ çš„ç¬”è®°/å•è¯æ•°é‡

**æ•°æ®æ¥æº**: `srs_schedule` è¡¨

**è®¡ç®—å…¬å¼**:
```sql
SELECT COUNT(*) FROM srs_schedule 
WHERE next_review_at <= NOW()
```

**è¯´æ˜**: ç»Ÿè®¡å½“å‰æ—¶é—´å·²è¶…è¿‡ `next_review_at` çš„è®°å½•æ•°ã€‚

---

### 2.2 è¿ç»­å­¦ä¹ å¤©æ•° (current_streak)

**å®šä¹‰**: ä»ä»Šå¤©å¾€å‰è¿ç»­å­¦ä¹ çš„å¤©æ•°

**æ•°æ®æ¥æº**: `attempts` è¡¨ + `vocab_learning_logs` è¡¨

**è®¡ç®—ç®—æ³•**:
```python
# 1. è·å–æ‰€æœ‰æœ‰æ´»åŠ¨çš„æ—¥æœŸ
attempt_dates = SELECT DISTINCT DATE(created_at) FROM attempts
vocab_dates = SELECT DISTINCT DATE(created_at) FROM vocab_learning_logs
all_dates = attempt_dates âˆª vocab_dates

# 2. ä»ä»Šå¤©å¼€å§‹å¾€å‰æ•°è¿ç»­å¤©æ•°
streak = 0
check_date = today
while check_date in all_dates:
    streak += 1
    check_date -= 1 day
```

**è¯´æ˜**: ä»»ä½•ä¸€å¤©æœ‰ç»ƒä¹ æ´»åŠ¨æˆ–æŸ¥è¯è®°å½•éƒ½ç®—æœ‰æ•ˆå­¦ä¹ ã€‚

---

### 2.3 é˜…è¯»å­—æ•° (total_words_read) - V2 æ··åˆä¿¡å·ç‰ˆ

**å®šä¹‰**: ç”¨æˆ·**çœŸå®é˜…è¯»**çš„è‹±æ–‡å•è¯æ€»æ•° (ç»è¿‡éªŒè¯)

**æ•°æ®æ¥æº**: `reading_sessions` è¡¨ (æ–°) + `vocab_learning_logs` è¡¨ (å›é€€)

**æ··åˆä¿¡å·é‡‡é›†**:
| ä¿¡å· | é‡‡é›†æ–¹å¼ | ä½œç”¨ |
|------|----------|------|
| æ—¶é—´æ¯” | active_seconds / expected_seconds | å¤ªå¿«=æ‰«è§† |
| é¡ºåºæ€§ | å¥å­è·³è·ƒæ£€æµ‹ | è·³è¿‡ä¸è®¡ |
| æ´»è·ƒåº¦ | Page Visibility API | æŒ‚æœºä¸ç®— |
| äº¤äº’ | ç”Ÿè¯ç‚¹å‡»æ¬¡æ•° | é«˜ç½®ä¿¡åº¦ |

**è´¨é‡è¯„ä¼°å…¬å¼**:
```python
# é¢„æœŸæ—¶é—´ (150 WPM)
expected_seconds = (sentences_covered * words_per_sentence) / 150 * 60
time_ratio = active_seconds / expected_seconds
jump_ratio = scroll_jump_count / sentences_covered

if has_interactions and time_ratio >= 0.5 and jump_ratio < 0.2:
    quality = "high", multiplier = 1.0
elif time_ratio >= 0.3 and jump_ratio < 0.3:
    quality = "medium", multiplier = 0.7
elif time_ratio >= 0.1:
    quality = "low", multiplier = 0.3
else:
    quality = "skimmed", multiplier = 0.0

validated_words = sequential_sentences * words_per_sentence * multiplier
```

**èšåˆæŸ¥è¯¢**:
```sql
SELECT SUM(validated_word_count), COUNT(*) 
FROM reading_sessions 
WHERE reading_quality IN ('high', 'medium', 'low')
```

**å‘åå…¼å®¹**: æ—  `reading_sessions` æ•°æ®æ—¶è‡ªåŠ¨å›é€€åˆ°æ—§ç‰ˆ `vocab_learning_logs` ä¼°ç®—ã€‚


---

### 2.4 é‡Œç¨‹ç¢‘å¾½ç«  (milestones)

**è¯æ±‡é‡é‡Œç¨‹ç¢‘**:
| é˜ˆå€¼ | å›¾æ ‡ | åç§° |
|------|------|------|
| 50 | ğŸŒ± | Seedling |
| 100 | ğŸŒ¿ | Sprout |
| 500 | ğŸŒ² | Sapling |
| 1000 | ğŸŒ³ | Tree |
| 2000 | ğŸŒ²ğŸŒ² | Grove |
| 3000 | ğŸ”ï¸ | Forest |
| 5000 | â›°ï¸ | Mountain |
| 10000 | ğŸ—» | Everest |

**è¿ç»­å­¦ä¹ é‡Œç¨‹ç¢‘**:
| é˜ˆå€¼ | å›¾æ ‡ | åç§° |
|------|------|------|
| 7å¤© | ğŸ”¥ | Week Warrior |
| 30å¤© | ğŸ’ª | Monthly Master |
| 100å¤© | ğŸ† | Century Club |
| 365å¤© | ğŸ‘‘ | Year Champion |

**è®¡ç®—æ–¹å¼**: å®æ—¶è®¡ç®—ï¼Œä¸æŒä¹…åŒ–åˆ°æ•°æ®åº“ã€‚

---

## 3. V3 æ¸¸æˆåŒ–æŒ‡æ ‡

### 3.1 æ¯æ—¥ç›®æ ‡ (goals_progress)

**å®šä¹‰**: ç”¨æˆ·è‡ªå®šä¹‰çš„æ¯æ—¥å­¦ä¹ ç›®æ ‡åŠå½“æ—¥å®Œæˆè¿›åº¦

**æ•°æ®æ¥æº**: `user_goals` è¡¨ + å¤šè¡¨æŸ¥è¯¢

**ç›®æ ‡ç±»å‹ä¸é»˜è®¤å€¼**:
| ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| new_words | 10 | ä»Šæ—¥æ–°å­¦å•è¯æ•° |
| review_words | 20 | ä»Šæ—¥å¤ä¹ å•è¯æ•° |
| study_minutes | 30 | ä»Šæ—¥å­¦ä¹ æ—¶é•¿ |
| reading_words | 500 | ä»Šæ—¥é˜…è¯»å­—æ•° |

**è¿›åº¦è®¡ç®—ç®—æ³•**:

```python
today_start = datetime.combine(today, datetime.min.time())
today_end = today_start + timedelta(days=1)

# æ–°å­¦å•è¯: ä»Šå¤©é¦–æ¬¡è§åˆ°çš„è¯
new_words = SELECT COUNT(DISTINCT word) FROM word_proficiency
            WHERE first_seen_at >= today_start 
            AND first_seen_at < today_end

# å¤ä¹ å•è¯: ä»Šå¤©å†æ¬¡è§åˆ°çš„è¯ (éé¦–æ¬¡)
review_words = SELECT COUNT(DISTINCT word) FROM word_proficiency
               WHERE last_seen_at >= today_start AND last_seen_at < today_end
               AND first_seen_at < today_start

# å­¦ä¹ æ—¶é•¿
study_minutes = SELECT SUM(duration_seconds)/60 FROM attempts
                WHERE created_at >= today_start AND created_at < today_end

# é˜…è¯»å­—æ•°: ä»Šæ—¥æŸ¥è¯çš„ä¸Šä¸‹æ–‡å¥å­æ€»å­—æ•°
reading_words = SUM(len(context_sentence.split())) 
                for logs where created_at in today
```

---

### 3.2 è®°å¿†æ›²çº¿ (memory_curve)

**å®šä¹‰**: å¯¹æ¯”ç”¨æˆ·å®é™…è®°å¿†ä¿æŒç‡ä¸è‰¾å®¾æµ©æ–¯é—å¿˜æ›²çº¿

**æ•°æ®æ¥æº**: `word_proficiency` è¡¨

**æ—¶é—´æ¡¶ (Time Buckets)**: 1å¤©, 3å¤©, 7å¤©, 14å¤©, 30å¤©

**å®é™…æ›²çº¿è®¡ç®—ç®—æ³•**:
```python
buckets = {1: [], 3: [], 7: [], 14: [], 30: []}

for word in word_proficiency where exposure_count > 1:
    days_since_first = (last_seen_at - first_seen_at).days
    
    # è®°å¿†ä¿æŒç‡ = 1 - (ä¸æ‡‚æ¬¡æ•° / æ€»å‡ºç°æ¬¡æ•°)
    retention = 1 - (huh_count / exposure_count)
    
    # åˆ†é…åˆ°æœ€è¿‘çš„æ—¶é—´æ¡¶
    for bucket in sorted(buckets.keys()):
        if days_since_first <= bucket:
            buckets[bucket].append(retention)
            break

# è®¡ç®—æ¯ä¸ªæ¡¶çš„å¹³å‡ä¿æŒç‡
actual_curve = [
    {"day": d, "retention": avg(buckets[d])}
    for d in sorted(buckets.keys())
]
```

**è‰¾å®¾æµ©æ–¯ç†è®ºæ›²çº¿**:
```python
# R = e^(-t/S)ï¼Œå…¶ä¸­ S = è®°å¿†ç¨³å®šæ€§å‚æ•° (é»˜è®¤ S=10)
ebbinghaus = [
    {"day": t, "retention": exp(-t / 10)}
    for t in [1, 3, 7, 14, 30]
]
```

**ç†è®ºå€¼å‚è€ƒ**:
| å¤©æ•° | ç†è®ºä¿æŒç‡ |
|------|-----------|
| 1å¤© | 90% |
| 3å¤© | 74% |
| 7å¤© | 50% |
| 14å¤© | 25% |
| 30å¤© | 5% |

---

## 4. å…¶ä»–æŒ‡æ ‡

### 4.1 è¯æ±‡åˆ†å¸ƒ (vocabulary.distribution)

**æ•°æ®æ¥æº**: `word_proficiency` è¡¨

```sql
SELECT status, COUNT(*) FROM word_proficiency GROUP BY status
```

è¿”å›: `{new: N, learning: N, mastered: N}`

---

### 4.2 éš¾è¯æ¦œ (vocabulary.difficult_words)

**å®šä¹‰**: æœ€éš¾æŒæ¡çš„å•è¯ (æŒ‰éš¾åº¦åˆ†æ•°æ’åº)

**æ•°æ®æ¥æº**: `word_proficiency` è¡¨çš„ `difficulty_score`

```sql
SELECT word, difficulty_score, huh_count 
FROM word_proficiency
WHERE difficulty_score > 0
ORDER BY difficulty_score DESC
LIMIT 10
```

**è¯´æ˜**: `difficulty_score` ç”±ç³»ç»Ÿæ ¹æ®ç”¨æˆ·åé¦ˆè‡ªåŠ¨è®¡ç®—ã€‚

---

### 4.3 æ´»åŠ¨çƒ­åŠ›å›¾ (activity.daily_counts)

**å®šä¹‰**: è¿‡å» N å¤©æ¯å¤©çš„æ´»åŠ¨æ•°é‡

**æ•°æ®æ¥æº**: `attempts` + `vocab_learning_logs`

```python
# åˆå¹¶ä¸¤ä¸ªè¡¨çš„æ—¥æœŸæ´»åŠ¨è®¡æ•°
attempt_counts = SELECT DATE(created_at), COUNT(*) FROM attempts
                 WHERE created_at >= cutoff GROUP BY DATE(created_at)

vocab_counts = SELECT DATE(created_at), COUNT(*) FROM vocab_learning_logs
               WHERE created_at >= cutoff GROUP BY DATE(created_at)

daily_counts = merge(attempt_counts, vocab_counts)
```

---

### 4.4 å­¦ä¹ æ¥æºåˆ†å¸ƒ (sources.distribution)

**å®šä¹‰**: ç”¨æˆ·ä»ä¸åŒæ¸ é“å­¦ä¹ çš„æ¯”ä¾‹

**æ•°æ®æ¥æº**: `vocab_learning_logs` è¡¨çš„ `source_type`

```sql
SELECT source_type, COUNT(*) FROM vocab_learning_logs GROUP BY source_type
```

**æ¥æºç±»å‹**:
- `epub`: EPUB ç”µå­ä¹¦é˜…è¯»
- `rss`: RSS æ–‡ç« é˜…è¯»
- `dictionary`: è¯å…¸æŸ¥è¯¢
- `voice`: è¯­éŸ³ç»ƒä¹ 
- `podcast`: æ’­å®¢

---

## API ç«¯ç‚¹

| ç«¯ç‚¹ | æ–¹æ³• | è¯´æ˜ |
|------|------|------|
| `/api/performance` | GET | è·å–å®Œæ•´ dashboard æ•°æ® |
| `/api/goals` | GET | è·å–ç”¨æˆ·ç›®æ ‡è®¾ç½® |
| `/api/goals` | PUT | æ›´æ–°ç”¨æˆ·ç›®æ ‡ |
| `/api/goals/progress` | GET | è·å–ä»Šæ—¥ç›®æ ‡è¿›åº¦ |
